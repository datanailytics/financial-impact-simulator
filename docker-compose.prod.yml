version: '3.8'

services:
  # Main application service
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: analytics-app
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - API_KEY=${API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - SENTRY_DSN=${SENTRY_DSN}
      - LOG_LEVEL=INFO
    ports:
      - "80:8000"
    volumes:
      - ./models:/app/models:ro
      - ./config:/app/config:ro
      - app-logs:/app/logs
      - app-data:/app/data
    networks:
      - analytics-prod-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx reverse proxy and load balancer
  nginx:
    image: nginx:alpine
    container_name: analytics-nginx
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - ./static:/usr/share/nginx/html/static:ro
      - nginx-logs:/var/log/nginx
    networks:
      - analytics-prod-network
    depends_on:
      - app
    restart: always
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL database (production configuration)
  postgres:
    image: postgres:15-alpine
    container_name: analytics-postgres-prod
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres-prod-data:/var/lib/postgresql/data
      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    networks:
      - analytics-prod-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: postgres -c config_file=/etc/postgresql/postgresql.conf

  # Redis for caching and sessions (production configuration)
  redis:
    image: redis:7-alpine
    container_name: analytics-redis-prod
    volumes:
      - redis-prod-data:/data
      - ./docker/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - analytics-prod-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Celery worker for background tasks
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: analytics-celery-worker
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CELERY_BROKER_URL=${REDIS_URL}
      - CELERY_RESULT_BACKEND=${REDIS_URL}
    volumes:
      - ./models:/app/models:ro
      - ./config:/app/config:ro
      - celery-logs:/app/logs
    networks:
      - analytics-prod-network
    depends_on:
      - redis
      - postgres
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G
    command: celery -A src.tasks.celery_app worker --loglevel=info --concurrency=4

  # Celery beat for scheduled tasks
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: analytics-celery-beat
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CELERY_BROKER_URL=${REDIS_URL}
      - CELERY_RESULT_BACKEND=${REDIS_URL}
    volumes:
      - ./config:/app/config:ro
      - celery-beat-logs:/app/logs
    networks:
      - analytics-prod-network
    depends_on:
      - redis
      - postgres
    restart: always
    command: celery -A src.tasks.celery_app beat --loglevel=info

  # Flower for Celery monitoring
  flower:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: analytics-flower
    environment:
      - ENVIRONMENT=production
      - CELERY_BROKER_URL=${REDIS_URL}
      - FLOWER_BASIC_AUTH=${FLOWER_USER}:${FLOWER_PASSWORD}
    ports:
      - "5555:5555"
    networks:
      - analytics-prod-network
    depends_on:
      - redis
    restart: always
    command: celery -A src.tasks.celery_app flower --port=5555

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: analytics-prometheus
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - analytics-prod-network
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: analytics-grafana-prod
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_SERVER_ROOT_URL=https://monitoring.yourdomain.com
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-prod-data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    networks:
      - analytics-prod-network
    depends_on:
      - prometheus
    restart: always

  # Loki for log aggregation
  loki:
    image: grafana/loki:latest
    container_name: analytics-loki
    volumes:
      - ./docker/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    ports:
      - "3100:3100"
    networks:
      - analytics-prod-network
    restart: always
    command: -config.file=/etc/loki/local-config.yaml

  # Promtail for log shipping
  promtail:
    image: grafana/promtail:latest
    container_name: analytics-promtail
    volumes:
      - ./docker/promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - app-logs:/app/logs:ro
      - nginx-logs:/nginx/logs:ro
      - celery-logs:/celery/logs:ro
    networks:
      - analytics-prod-network
    depends_on:
      - loki
    restart: always
    command: -config.file=/etc/promtail/config.yml

  # PostgreSQL backup service
  postgres-backup:
    image: prodrigestivill/postgres-backup-local:latest
    container_name: analytics-postgres-backup
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_EXTRA_OPTS=-Z9 --schema=public --blobs
      - SCHEDULE=@daily
      - BACKUP_KEEP_DAYS=7
      - BACKUP_KEEP_WEEKS=4
      - BACKUP_KEEP_MONTHS=6
      - HEALTHCHECK_PORT=8080
    volumes:
      - postgres-backups:/backups
    networks:
      - analytics-prod-network
    depends_on:
      - postgres
    restart: always

  # Redis Sentinel for high availability
  redis-sentinel:
    image: redis:7-alpine
    container_name: analytics-redis-sentinel
    volumes:
      - ./docker/redis/sentinel.conf:/etc/redis/sentinel.conf:ro
    networks:
      - analytics-prod-network
    restart: always
    command: redis-sentinel /etc/redis/sentinel.conf

  # Node exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: analytics-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - analytics-prod-network
    restart: always
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

  # Cadvisor for container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: analytics-cadvisor
    ports:
      - "8090:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - analytics-prod-network
    restart: always
    privileged: true
    devices:
      - /dev/kmsg

networks:
  analytics-prod-network:
    driver: bridge
    name: analytics-prod-network
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres-prod-data:
    driver: local
    name: analytics-postgres-prod-data
  redis-prod-data:
    driver: local
    name: analytics-redis-prod-data
  app-logs:
    driver: local
    name: analytics-app-logs
  app-data:
    driver: local
    name: analytics-app-data
  nginx-logs:
    driver: local
    name: analytics-nginx-logs
  celery-logs:
    driver: local
    name: analytics-celery-logs
  celery-beat-logs:
    driver: local
    name: analytics-celery-beat-logs
  prometheus-data:
    driver: local
    name: analytics-prometheus-data
  grafana-prod-data:
    driver: local
    name: analytics-grafana-prod-data
  loki-data:
    driver: local
    name: analytics-loki-data
  postgres-backups:
    driver: local
    name: analytics-postgres-backups